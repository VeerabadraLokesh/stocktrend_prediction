{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ce909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40817f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "numerical_df = yf.download('AMZN', \"2015-10-01\", \"2020-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81889085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()[:period+1]\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()[:period+1]\n",
    "    \n",
    "    for i in range(period+1, len(data)):\n",
    "        avg_gain = pd.concat(\n",
    "            [avg_gain, \n",
    "             pd.Series([(avg_gain.iloc[-1] * (period - 1) + gain.iloc[i]) / period], index=[gain.index[i]])\n",
    "            ]\n",
    "        )\n",
    "        avg_loss = pd.concat(\n",
    "            [avg_loss,\n",
    "                pd.Series([(avg_loss.iloc[-1] * (period - 1) + loss.iloc[i]) / period], index=[loss.index[i]])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "n_days = 50\n",
    "# sp500_tickers = sorted(sp500_company_tickers_in_kaggle_df.split(\" \"))\n",
    "\n",
    "# for comp in sp500_tickers:\n",
    "numerical_df['RSI'] = calculate_rsi(numerical_df['Close'], 50)\n",
    "numerical_df['EMA'] = numerical_df['Close'].ewm(span=n_days, adjust=False).mean()\n",
    "numerical_df['SMA'] = numerical_df['Close'].rolling(window=14).mean()\n",
    "temp_12 = numerical_df['Close'].ewm(span=12, adjust=False).mean()\n",
    "temp_26 = numerical_df['Close'].ewm(span=26, adjust=False).mean()\n",
    "numerical_df['MACD'] = temp_12 - temp_26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df =  numerical_df[numerical_df.index >= pd.Timestamp(2016, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f621b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = numerical_df.drop(columns='Adj Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47832194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = numerical_df.drop(columns=['Close']), numerical_df.Close.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6798ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_trans = ss.fit_transform(X)\n",
    "y_trans = mm.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2da439",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba208d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95b0dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba79789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Fetch historical stock data\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_ema(data, span=50):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def calculate_sma(data, window=14):\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "def calculate_macd(data, span_short=12, span_long=26):\n",
    "    ema_short = calculate_ema(data, span=span_short)\n",
    "    ema_long = calculate_ema(data, span=span_long)\n",
    "    return ema_short - ema_long\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_technical_indicators(data):\n",
    "    # Compute RSI\n",
    "    data['RSI'] = calculate_rsi(data['Close'], period=14)\n",
    "\n",
    "    # Compute EMA\n",
    "    data['EMA'] = calculate_ema(data['Close'], span=50)\n",
    "\n",
    "    # Compute SMA\n",
    "    data['SMA'] = calculate_sma(data['Close'], window=14)\n",
    "\n",
    "    # Compute MACD\n",
    "    data['MACD'] = calculate_macd(data['Close'], span_short=12, span_long=26)\n",
    "\n",
    "    # Handle missing values by filling with the mean of each column\n",
    "    data_filled = data.fillna(data.mean())\n",
    "\n",
    "    return data_filled\n",
    "\n",
    "# Step 3: Prepare data\n",
    "def prepare_data(data, n_context_days = 5):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_data = scaler.fit_transform(data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']])\n",
    "    scaled_data = data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']].values\n",
    "    X, y = [], []\n",
    "    for i in range(n_context_days, len(data)):\n",
    "        X.append(scaled_data[i-n_context_days:i])\n",
    "        y.append(scaled_data[i, 0])  # Closing price\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "#     inputs = tf.expand_dims(inputs, axis=1)\n",
    "#     print(inputs.shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    \n",
    "#     n_timesteps, n_features, n_outputs = 5, 1, 5\n",
    "    inputs = keras.Input(shape=(input_shape))\n",
    "    \n",
    "#     print(\"input_shape\",inputs.shape)\n",
    "    \n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test):\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=4,\n",
    "        ff_dim=3,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"mean_squared_error\", \"mean_squared_error\", \"mape\"],\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "#         validation_data=(x_test, y_test),\n",
    "        validation_split=0.2,\n",
    "        epochs=25,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Step 7: Predict next day's closing price\n",
    "def predict_next_day_price(model, last_data_point, scaler):\n",
    "    last_data_point = last_data_point.reshape((1, last_data_point.shape[0], last_data_point.shape[1]))\n",
    "    predicted_scaled_price = model.predict(last_data_point)\n",
    "    predicted_price = scaler.inverse_transform([[predicted_scaled_price[0][0], 0, 0, 0, 0]])[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "\n",
    "\n",
    "# Fetch data\n",
    "symbol = 'AAPL'  # Example symbol\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2022-01-01'\n",
    "data = fetch_stock_data(symbol, start_date, end_date)\n",
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_with_technical_indicators)\n",
    "\n",
    "# X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef843f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=False,\n",
    "    rankdir='TB',\n",
    "    # rankdir='LR',\n",
    "    expand_nested=False,\n",
    "    dpi=75,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    "    # **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above exp uses all open, close, rma, ema features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43993a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eee488",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_train, label='Actual Stock Prices')\n",
    "plt.plot(y_train_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875faccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b126de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_with_technical_indicators)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above exp - using only close feature, output only next day price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e51308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2de87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e8016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef723e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ta\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Fetch historical stock data\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_ema(data, span=50):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def calculate_sma(data, window=14):\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "def calculate_macd(data, span_short=12, span_long=26):\n",
    "    ema_short = calculate_ema(data, span=span_short)\n",
    "    ema_long = calculate_ema(data, span=span_long)\n",
    "    return ema_short - ema_long\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_technical_indicators(data):\n",
    "    # Compute RSI\n",
    "    data['RSI'] = calculate_rsi(data['Close'], period=14)\n",
    "\n",
    "    # Compute EMA\n",
    "    data['EMA'] = calculate_ema(data['Close'], span=50)\n",
    "\n",
    "    # Compute SMA\n",
    "    data['SMA'] = calculate_sma(data['Close'], window=14)\n",
    "\n",
    "    # Compute MACD\n",
    "    data['MACD'] = calculate_macd(data['Close'], span_short=12, span_long=26)\n",
    "\n",
    "    # Handle missing values by filling with the mean of each column\n",
    "    data_filled = data.fillna(data.mean())\n",
    "\n",
    "    return data_filled\n",
    "\n",
    "# Step 3: Prepare data\n",
    "def prepare_data(data, n_context_days = 5):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_data = scaler.fit_transform(data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']])\n",
    "    scaled_data = data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']].values\n",
    "    X, y = [], []\n",
    "    for i in range(n_context_days, len(data)-5):\n",
    "        X.append(scaled_data[i-n_context_days:i, 0])\n",
    "        y.append(scaled_data[i:i+5, 0])  # Closing price\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    \n",
    "#     n_timesteps, n_features, n_outputs = 5, 1, 5\n",
    "    inputs = keras.Input(shape=(input_shape))\n",
    "    \n",
    "#     print(\"input_shape\",inputs.shape)\n",
    "    \n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(5, activation=\"linear\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_with_technical_indicators)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test[:,0], label='Actual Stock Prices')\n",
    "plt.plot(y_pred[:,0], label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features only close prices ; output next 5 days price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13772d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41981d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfdecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_with_technical_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed13eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_technical_indicators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08624eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19f107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ac2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17292613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install ta\n",
    "\n",
    "\n",
    "# ! pip install ta\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Fetch historical stock data\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "def calculate_rsi(data, period=14):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_ema(data, span=50):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def calculate_sma(data, window=14):\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "def calculate_macd(data, span_short=12, span_long=26):\n",
    "    ema_short = calculate_ema(data, span=span_short)\n",
    "    ema_long = calculate_ema(data, span=span_long)\n",
    "    return ema_short - ema_long\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_technical_indicators(data):\n",
    "    # Compute RSI\n",
    "    data['RSI'] = calculate_rsi(data['Close'], period=14)\n",
    "\n",
    "    # Compute EMA\n",
    "    data['EMA'] = calculate_ema(data['Close'], span=50)\n",
    "\n",
    "    # Compute SMA\n",
    "    data['SMA'] = calculate_sma(data['Close'], window=14)\n",
    "\n",
    "    # Compute MACD\n",
    "    data['MACD'] = calculate_macd(data['Close'], span_short=12, span_long=26)\n",
    "\n",
    "    # Handle missing values by filling with the mean of each column\n",
    "    data_filled = data.fillna(data.mean())\n",
    "\n",
    "    return data_filled\n",
    "\n",
    "# Step 3: Prepare data\n",
    "def prepare_data(data, n_context_days = 5):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_data = scaler.fit_transform(data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']])\n",
    "    scaled_data = data[['Close', 'RSI', 'EMA', 'SMA', 'MACD']].values\n",
    "    X, y = [], []\n",
    "    for i in range(n_context_days, len(data)):\n",
    "        X.append(scaled_data[i-n_context_days:i, 0])\n",
    "        y.append(scaled_data[i, 0])  # Closing price\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \n",
    "#     model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "#   model.add(Dense(50, activation='relu'))\n",
    "#   model.add(Dense(n_outputs)\n",
    "            \n",
    "    model = Sequential([\n",
    "        LSTM(units=200, activation='relu', input_shape=input_shape),\n",
    "#         Dropout(0.2),\n",
    "        Dense(units=50, activation='relu'),\n",
    "#         Dropout(0.2),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"mae\", \"mape\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train):\n",
    "    print(\"check x_train\", x_train.shape[1:])\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    model = build_model(input_shape)\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=25,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 7: Predict next day's closing price\n",
    "def predict_next_day_price(model, last_data_point, scaler):\n",
    "    last_data_point = last_data_point.reshape((1, last_data_point.shape[0], last_data_point.shape[1]))\n",
    "    predicted_scaled_price = model.predict(last_data_point)\n",
    "    predicted_price = scaler.inverse_transform([[predicted_scaled_price[0][0], 0, 0, 0, 0]])[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_with_technical_indicators)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c54f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa66d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip stocktrend_prediction/ticker_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c335236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d52c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "import lzma\n",
    "import pickle\n",
    "\n",
    "with lzma.open('ticker_data/embeddings/AAPL.xz') as rf:\n",
    "    data = pickle.load(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "embedding_df.index = pd.to_datetime(embedding_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23187879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentiment\n",
    "\n",
    "import lzma\n",
    "import pickle\n",
    "\n",
    "with lzma.open('ticker_data/sentiments/AAPL.xz') as rf:\n",
    "    sentiment_data = pickle.load(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame.from_dict(sentiment_data, orient='index')\n",
    "sentiment_df.index = pd.to_datetime(sentiment_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc2cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d7134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_technical_indicators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_sentiment = data_with_technical_indicators.join(sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor = 0.9 \n",
    "\n",
    "def apply_decay(df):\n",
    "    \n",
    "    series = df['score']\n",
    "    mask = series.isna()\n",
    "    # Calculate the distance since the last non-NaN value\n",
    "    distance = mask.groupby((mask != mask.shift()).cumsum()).cumcount() + 1\n",
    "    # Apply decay factor to the filled values\n",
    "    decayed_values = series.ffill() * (decay_factor ** distance)\n",
    "    \n",
    "    df['decayed_score'] = decayed_values\n",
    "    \n",
    "    return np.where(df['score'].isna(), df['decayed_score'], df['score'])\n",
    "    \n",
    "\n",
    "\n",
    "data_w_sentiment['decayed_score'] = apply_decay(data_w_sentiment)\n",
    "\n",
    "\n",
    "data_w_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_sentiment['label'] = data_w_sentiment['label'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_sentiment['decayed_score'] = np.where(\n",
    "    data_w_sentiment['label']=='neutral', 0, data_w_sentiment['decayed_score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568548cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_sentiment['decayed_score'] = np.where(\n",
    "    data_w_sentiment['label']=='negative', -data_w_sentiment['decayed_score'], data_w_sentiment['decayed_score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_sentiment = data_w_sentiment.drop(columns=['score', 'label']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db833ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba92ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce2134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51362bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "data_w_news = data_with_technical_indicators.join(embedding_df)\n",
    "data_w_news = data_w_news.fillna(0)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_w_news)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e48a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above exp - financial + news data ; close price output is only next day price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1466d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute technical indicators\n",
    "data_with_technical_indicators = compute_technical_indicators(data)\n",
    "data_w_news = data_with_technical_indicators.join(embedding_df)\n",
    "data_w_news = data_w_news.fillna(0)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "if data_with_technical_indicators.isnull().values.any():\n",
    "    print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "    exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_w_news)\n",
    "\n",
    "# X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above exp: all finanical + news\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e2aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1470f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c09851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute technical indicators\n",
    "# data_with_technical_indicators = compute_technical_indicators(data)\n",
    "# data_w_news = data_with_technical_indicators.join(embedding_df)\n",
    "# data_w_news = data_w_news.fillna(0)\n",
    "\n",
    "# Check for missing values after computing technical indicators\n",
    "# if data_with_technical_indicators.isnull().values.any():\n",
    "#     print(\"There are missing values after computing technical indicators. Please handle them appropriately.\")\n",
    "#     exit()\n",
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_w_sentiment)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above exp financial close + sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f330f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data\n",
    "X, y, scaler = prepare_data(data_w_sentiment)\n",
    "\n",
    "# X = X.reshape(X.shape[0], 1, X.shape[-1])\n",
    "# Split data into training and testing sets\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate model\n",
    "# loss = evaluate_model(model, X_test, y_test)\n",
    "print(\"Test Loss:\", loss)  # Test loss: Represents the average loss (error) between the predicted values and the actual values. Lower values indicate better performance.\n",
    "# Predict next day's closing price\n",
    "last_data_point = X_test[-1]\n",
    "next_day_price = predict_next_day_price(model, last_data_point, scaler)\n",
    "print(\"Predicted Next Day's Closing Price:\", next_day_price)\n",
    "\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)  # Mean Absolute Error (MAE): Average magnitude of the errors in the predictions. Lower values indicate better performance.\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # Mean Squared Error (MSE): Average of the squared differences between the predicted values and the actual values. Lower values indicate better performance.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Root Mean Squared Error (RMSE): Standard deviation of the residuals (prediction errors). Lower values indicate better performance.\n",
    "\n",
    "# Visualize model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual Stock Prices')\n",
    "plt.plot(y_pred, label='Predicted Stock Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4802fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers\n",
    "\n",
    "\n",
    "# financial (close) ; using only close feature, output only next day price\n",
    "Mean Absolute Error (MAE): 4.334137613123113\n",
    "Mean Squared Error (MSE): 29.039432252151695\n",
    "Root Mean Squared Error (RMSE): 5.388824756118137\n",
    "    \n",
    "    \n",
    "    \n",
    "# financial (close) + news data ; close price output is only next day price\n",
    "Mean Absolute Error (MAE): 2.743355014107444\n",
    "Mean Squared Error (MSE): 12.688472780434411\n",
    "Root Mean Squared Error (RMSE): 3.562088261179727\n",
    "\n",
    "    \n",
    "# all financial\n",
    "Mean Absolute Error (MAE): 16.880988359451294\n",
    "Mean Squared Error (MSE): 309.14230541645105\n",
    "Root Mean Squared Error (RMSE): 17.5824431014706\n",
    "    \n",
    "    \n",
    "#  all finanical + news\n",
    "Mean Absolute Error (MAE): 8.653478340669112\n",
    "Mean Squared Error (MSE): 101.70793979023455\n",
    "Root Mean Squared Error (RMSE): 10.085035438224029\n",
    "    \n",
    "    \n",
    "    \n",
    "#  financial close + sentiment\n",
    "Mean Absolute Error (MAE): 2.257353359181098\n",
    "Mean Squared Error (MSE): 8.602969036914159\n",
    "Root Mean Squared Error (RMSE): 2.9330818326317045\n",
    "\n",
    "    \n",
    "\n",
    "#  all financial  + sentiment\n",
    "Mean Absolute Error (MAE): 5.52126697857027\n",
    "Mean Squared Error (MSE): 45.17546689611988\n",
    "Root Mean Squared Error (RMSE): 6.721269738384249"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
