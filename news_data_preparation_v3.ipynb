{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280c1ba-9333-4c81-b71a-e4066457f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from dataset import get_path\n",
    "dataset_name ='miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests'\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import lzma\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c98f83-5d39-4626-9915-b3d786c2c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dir = \"datasets/ticker_data/\"\n",
    "os.makedirs(ticker_dir, exist_ok=True)\n",
    "embeddings_dir = \"datasets/ticker_data/embeddings/\"\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "sentiments_dir = \"datasets/ticker_data/sentiments/\"\n",
    "os.makedirs(sentiments_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b739a-39f9-4d3f-8a01-2fe0359a09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = \"datasets/processed/\"\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "processed_count_file = os.path.join(processed_data_dir, \"processed.count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07203532-1390-4935-9fa4-d6c07273f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['AAPL','META', 'GOOGL','AMZN', 'MSFT', \"FB\", \"TSLA\", \"NFLX\"]\n",
    "companies = []\n",
    "companies = {c:1 for c in companies}\n",
    "def is_valid_ticker(t):\n",
    "    return t in companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813da015-ff7e-4acb-a79b-116a7966d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73066885-f23e-45a1-bd87-e6d0a5cd02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75363ce-46ea-4be6-bdc3-d336e0f49508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvs = [os.path.join(processed_data_dir, f) for f in sorted(os.listdir(processed_data_dir)) if f.endswith('.csv')]\n",
    "\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_id = \"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\"\n",
    "model_id = 'paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "sentence_model = SentenceTransformer(model_id)\n",
    "sentence_model.to(device)\n",
    "sentence_model.eval()\n",
    "\n",
    "task = \"text-classification\"\n",
    "model_id = \"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\"\n",
    "classifier = pipeline(task, model_id, device=device)\n",
    "classifier.model.eval()\n",
    "\n",
    "sentiments = {c: {} for c in companies}\n",
    "embeddings = {c: {} for c in companies}\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for csv in csvs:\n",
    "        print(csv)\n",
    "        df = pd.read_csv(csv)\n",
    "        \n",
    "        # display(df)\n",
    "        for row in tqdm(df.iterrows()):\n",
    "            ticker = row[1]['Ticker']\n",
    "            if not is_valid_ticker(ticker):\n",
    "                continue\n",
    "            date = row[1]['Date']\n",
    "            news = row[1]['News']\n",
    "            # news = json.loads(news)\n",
    "            news = \" \".join(ast.literal_eval(news))\n",
    "            embedding = sentence_model.encode(news)\n",
    "            try:\n",
    "                result = classifier(news[:16384])[0]\n",
    "            except Exception as e:\n",
    "                print(len(news), len(row[1]['News']))\n",
    "                raise e\n",
    "            sentiments[ticker][date] = result\n",
    "            embeddings[ticker][date] = embedding\n",
    "            # print(type(embedding))\n",
    "            # print(csv, ticker, date, news, type(news), type(embeddings), embeddings.shape)\n",
    "        #     break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29de5e1-610f-4bb6-860b-296fe66031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in sentiments:\n",
    "    if not sentiments[ticker]:\n",
    "        continue\n",
    "    with lzma.open(f\"{sentiments_dir}/{ticker}.xz\", \"wb\") as f:\n",
    "        pickle.dump(sentiments[ticker], f)\n",
    "\n",
    "    with lzma.open(f\"{embeddings_dir}/{ticker}.xz\", \"wb\") as f:\n",
    "        pickle.dump(embeddings[ticker], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1b3cd-c9b7-41dd-8fca-c1d4f7e7c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be737e-187d-4bd4-be45-1cfe9064358e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0fdf8-70a3-494b-a4d5-d254eb63e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "task = \"text-classification\"\n",
    "# task = \"fill-mask\"\n",
    "model_id = \"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\"\n",
    "\n",
    "classifier = pipeline(task, model_id, device='cuda')\n",
    "text = \"Tesla cars are not as good as expected\"\n",
    "text = news\n",
    "result = classifier(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a23034-5766-424a-a621-17d143635a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe91e4-848c-4b7a-ac8a-7204ced813e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47f9ff-ef81-45f2-a04b-e2ed0dd2230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42f2c3-adce-4cb4-9d81-d834973b44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b435b-2aed-4767-8339-f3731a0bdce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb99e3a-2fab-48f0-a32f-0cfc2cca2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_dataset\n",
    "dataset_name ='miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests'\n",
    "file_name = 'raw_analyst_ratings.csv'\n",
    "raw_analyst_ratings_df = load_dataset(dataset_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056119f-3cca-41e2-99f9-e45a175e18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = os.path.join(get_path(dataset_name),'raw_data/data.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7c77-e349-4399-9f7f-4c8d7aa8f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings_df.sort_values(by=['date'], ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a58ec0-6e96-4d1a-bcaf-a8623e205444",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358564e-a3c9-40dc-93e1-be2618f827f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce192d-5284-4381-9054-035cbfdc75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings_df[raw_analyst_ratings_df['Unnamed: 0'] == 4]['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32917093-c968-4981-86a4-045ead47cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_data = {}\n",
    "\n",
    "for idx, row in tqdm(raw_analyst_ratings_df.iterrows()):\n",
    "    idx_data[row['Unnamed: 0']] = row['date'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ae525-a761-4b2e-a1ca-15d659afbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824e3bd-fe60-4982-90d6-78b82a02e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "if os.path.isfile(processed_count_file):\n",
    "    with open(processed_count_file, 'r') as rf:\n",
    "        try:\n",
    "            x = int(rf.read())\n",
    "            print(x)\n",
    "            start = x\n",
    "        except:\n",
    "            print(rf.read())\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f8699-a812-497d-99a5-6947fe50d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df, st, end):\n",
    "    file_name = os.path.join(processed_data_dir, f\"{st:07d}_{end:07d}.csv\")\n",
    "    df.to_csv(file_name)\n",
    "    with open(processed_count_file, 'w') as wf:\n",
    "        wf.write(str(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d9886-52ce-4e81-a8e9-33ada6e7953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(news, st, end):\n",
    "    news_df = pd.DataFrame.from_dict(news).reset_index().rename(columns={'index':'Ticker'})\n",
    "    news_df_processed = pd.melt(news_df, id_vars=['Ticker'], var_name='Date', value_name='News')\n",
    "    news_df_processed = news_df_processed[~news_df_processed['News'].isna()]\n",
    "    save_df_to_csv(news_df_processed, st, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18377fb-5bc1-460e-82b6-3537a3f0be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "news = defaultdict(lambda: defaultdict(list))\n",
    "text = \"\"\n",
    "end = start\n",
    "parse = False\n",
    "prev_text=None\n",
    "with open(raw_data_path, 'r', encoding=\"utf8\") as rf:\n",
    "    for l in rf:\n",
    "        # if skip:\n",
    "        #     skip -= 1\n",
    "        #     continue\n",
    "        text += l\n",
    "        if text.endswith(\"</div>\\n\"):\n",
    "            if parse:\n",
    "                try:\n",
    "                    idx = int(text[:10])\n",
    "                except Exception as e:\n",
    "                    # print(prev_text)\n",
    "                    # print(text)\n",
    "                    print(e)\n",
    "                    text = \"\"\n",
    "                    count += 1\n",
    "                    continue\n",
    "                    # raise e\n",
    "                # dt = raw_analyst_ratings_df[raw_analyst_ratings_df['Unnamed: 0'] == idx]['date'].iloc[0][:10]\n",
    "                dt = idx_data[idx]\n",
    "                # print(dt)\n",
    "                html = text[10:]\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                for p in soup.find_all(\"p\", {\"class\": \"block core-block\"}):\n",
    "                    ticker = p.find(\"span\", {\"class\": \"ticker\"})\n",
    "                    if ticker:\n",
    "                        ticker = ticker.get_text()\n",
    "                        # if is_valid_ticker(ticker):\n",
    "                        tnews = p.get_text(strip=False).replace('\\xa0', ' ')\n",
    "                        news[dt][ticker].append(tnews)\n",
    "                for ul in soup.find_all(\"ul\", {\"class\": \"block core-block\"}):\n",
    "                    for li in ul.find_all(\"li\"):\n",
    "                        # print(li)\n",
    "                        ticker = li.find(\"span\", {\"class\": \"ticker\"})\n",
    "                        if ticker:\n",
    "                            ticker = ticker.get_text()\n",
    "                            # if is_valid_ticker(ticker):\n",
    "                            tnews = li.get_text(strip=False).replace('\\xa0', ' ')\n",
    "                            news[dt][ticker].append(tnews)\n",
    "            # prev_text = text\n",
    "            text = \"\"\n",
    "            count += 1\n",
    "        if count == start:\n",
    "            parse = True\n",
    "        # if count % 5000 == 0:\n",
    "        #     print(count)\n",
    "        if count % 10000 == 0 and len(news) > 0:\n",
    "            save_dict(news, end, count)\n",
    "            end = count + 1\n",
    "            news = defaultdict(lambda: defaultdict(list))\n",
    "        # if count == 10000:\n",
    "        #     break\n",
    "        #     break\n",
    "        # break\n",
    "save_dict(news, end, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6062d1-cd53-44ee-9386-607fa47ad80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
